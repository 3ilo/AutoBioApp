# -*- coding: utf-8 -*-
"""CreateFinetuningDataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t_esKCDvlB-iNYr8deY1ktQXOLAZsEYd
"""

# IMPORTANT: need to log into HF to publish dataset `> hf auth login`

import os
import csv

from PIL import Image
from pathlib import Path
from transformers import pipeline

# parameters
TARGET_WIDTH = 512
TARGET_HEIGHT = 512
DATA_DIR = "AutobioLoraFinetuning"
IMAGES_DIR = os.path.join(DATA_DIR, "images")
PROMPTS_DIR = os.path.join(DATA_DIR, "prompts")
os.makedirs(PROMPTS_DIR, exist_ok=True)
DATASET_NAME = "dataset.csv"
SUPPORTED_IMG_TYPES = (".png", ".jpg", ".jpeg", ".webp")
LABELING_MODEL = "Salesforce/blip-image-captioning-base"
HF_USER_NAME = "3ilo"
HF_DATASET_NAME = "test-style-dataset"

# TODO: replace. Have noticed this includes stylistic info -- not desirable in this case.
captioner = pipeline("image-to-text", model=LABELING_MODEL)

# process images
# !!! TODO: add special token in the labels.
for img_file in os.listdir(IMAGES_DIR):
    if not img_file.lower().endswith(SUPPORTED_IMG_TYPES):
        continue

    img_path = os.path.join(IMAGES_DIR, img_file)
    prompt_path = os.path.join(PROMPTS_DIR, os.path.splitext(img_file)[0] + ".txt")

    # resize if needed
    img = Image.open(img_path)
    if img.size != (TARGET_WIDTH, TARGET_HEIGHT):
        img_resized = img.resize((TARGET_WIDTH, TARGET_HEIGHT), Image.LANCZOS)
        img_resized.save(img_path)
        print(f"Resized {img_file} to {TARGET_WIDTH}x{TARGET_HEIGHT}")

    # generate prompt if needed
    if not os.path.exists(prompt_path):
        prompt_text = captioner(img_path)[0]['generated_text']
        with open(prompt_path, "w", encoding="utf-8") as f:
            f.write(prompt_text)
        print(f"Generated prompt for {img_file}: {prompt_text}")

# little bit of post-processing
import os

target_dir = f"{DATA_DIR}/prompts"

# phrases to remove from prompts
phrases_to_remove = [
    "a drawing of",
    "a black and white",
    "drawing of",
]

def clean_file_contents(directory, phrases):
    for filename in os.listdir(directory):
        if not filename.endswith(".txt"):
            continue

        file_path = os.path.join(directory, filename)

        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read()

        new_content = content
        for phrase in phrases:
            new_content = new_content.replace(phrase, "")

        new_content = " ".join(new_content.split())

        if new_content != content:
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(new_content)
            print(f"Updated: {filename}")

clean_file_contents(target_dir, phrases_to_remove)

images_dir = os.path.join(DATA_DIR, "images")
prompts_dir = os.path.join(DATA_DIR, "prompts")
csv_file = os.path.join(DATA_DIR, DATASET_NAME)

image_files = sorted([f for f in os.listdir(images_dir) if f.lower().endswith(SUPPORTED_IMG_TYPES)])

rows = []

# combine image and prompt files into csv
for img_file in image_files:
    prompt_file = os.path.splitext(img_file)[0] + ".txt"
    prompt_path = os.path.join(prompts_dir, prompt_file)

    if not os.path.exists(prompt_path):
        print(f"Warning: No prompt file found for {img_file}, skipping.")
        continue

    with open(prompt_path, "r", encoding="utf-8") as f:
        prompt_text = f.read().strip()

    img_rel_path = os.path.join(images_dir, img_file)

    rows.append([img_rel_path, prompt_text])

# write csv
with open(csv_file, "w", newline="", encoding="utf-8") as f:
    writer = csv.writer(f)
    writer.writerow(["image", "prompt"])
    writer.writerows(rows)

print(f"CSV successfully created at {csv_file} with {len(rows)} entries.")


# create dataset
from datasets import Dataset, DatasetDict, Features, Value, Image

dataset_path = os.path.join(dataset_dir, DATASET_NAME)
dataset = Dataset.from_csv(dataset_path)
dataset = dataset.cast_column("image", Image())

# optional
dataset = dataset.train_test_split(test_size=0.1)

dataset.push_to_hub(f"{HF_USER_NAME}/{HF_DATASET_NAME}")